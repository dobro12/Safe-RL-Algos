# base
name: ipo

# for RL
discount_factor: 0.99
n_steps: 5000
actor_lr: 3e-5
critic_lr: 3e-4
n_actor_iters: 20
n_critic_iters: 40
clip_ratio: 0.2
max_kl: 0.01
max_grad_norm: 1.0
gae_coeff: 0.97

# for constraint
con_threshold: 0.025
con_t: 50.0

# for backup
backup_files: [
    algos/ipo/agent.py,
    algos/ipo/storage.py,
    algos/ipo/safetygym.yaml,
]

# for logging
logging:
    metric: [fps, kl, entropy, constraint]
    rollout: [reward_sum, cost_sum, eplen]
    train: [actor_loss, cost_critic_loss, reward_critic_loss]

# for model
model:
    actor:
        mlp:
            shape: [512, 512]
            activation: ReLU
        out_activation: tanh
        log_std_init: 0.0
    reward_critic:
        mlp:
            shape: [512, 512]
            activation: ReLU
        clip_range: [-np.inf, np.inf]
    cost_critic:
        mlp:
            shape: [512, 512]
            activation: ReLU
        clip_range: [-np.inf, np.inf]
